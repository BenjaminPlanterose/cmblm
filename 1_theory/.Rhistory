# Load libraries
library(MASS)
library(fastmatrix)
library(penalized)
library(ridge)
library(matrixcalc)
# Generate X
set.seed(1)
n = 100
m = 10
mu = rnorm(m) # Generate mean vector
Sigma = rWishart(n = 1, df = m, Sigma = diag(m))[,,1] # Generate random Covariance matrix
X = mvrnorm(n = n, mu = mu, Sigma = Sigma) # Without intercept column
X_ = cbind(1, X) # With intercept column
# Generate y
THETA = rnorm(m+1)
y = X_ %*% THETA + rnorm(n, sd = 3)
X_y = cbind(X_, y) # Extended X matrix
# Reduced QR decomposition of X
dim(X_) # 100  11
QR = qr(X_)
R = qr.R(QR, complete = F); dim(R) # 11 11
Q = qr.Q(QR, complete = F); dim(Q) # 100  11
# OLS estimates
(theta_ols = coef(lm(y ~ X))) # lm function
solve(t(X_) %*% X_) %*% t(X_) %*% y # From Normal equation
ginv(X_) %*% y # From pseudoinverse
backsolve(R, t(Q) %*% y) # From QR
sweep.operator(t(X_y) %*% X_y, k = 1:(m+1))[1:(m+1),m+2] # From sweep operation
# Exclude columns operation
omega = c(2,4,7)
I = diag(m+1)[,-omega]
mean(X_ %*% I == X_[,-omega]) # 1
I %*% t(I) # Unitary matrix with zeros in Ajj for j in omega
t(I) %*% I # Unitary matrix of order m+1-|omega|
head(X_ %*% I %*% t(I)) # substitutes columns in omega by zeros
X_ %*% I
X_[,-omega]; X_ %*% I # Equivalence
X_[,-omega] == X_ %*% I # Equivalence
# Interpreting R
R[1,1]^2; nrow(X_) # n
R[1,]/R[1,1]; colMeans(X_) # mu
1/(R[1,1]^2 - 1) * (t(R) %*% R - R[1,] %*% t(R[1,])); cov(X_) # covariance matrix
chol((n-1)*cov(X_) + n*colMeans(X_) %*% t(colMeans(X_))); R # R from n, mu and covariance matrix; sign does not match because of sign multiplicity in Cholesky (but does not affect in any way)
chol((n-1)*cov(X_) + n*colMeans(X_) %*% t(colMeans(X_))) == R # R from n, mu and covariance matrix; sign does not match because of sign multiplicity in Cholesky (but does not affect in any way)
chol((n-1)*cov(X_) + n*colMeans(X_) %*% t(colMeans(X_))); R # R from n, mu and covariance matrix; sign does not match because of sign multiplicity in Cholesky (but does not affect in any way)
mean(y); t(R[1,]/R[1,1]) %*% theta_ols # mean(y)
# Cmb-lm estimates
omega = c(2,4,7); omega_c = (1:(m+1))[!(1:(m+1) %in% omega)]
(theta_omega = coef(lm(y ~ X[,-(omega-1)]))) # lm function; omega-1 as it does not include the intercept
ginv(R %*% diag(m+1)[,-omega]) %*% R %*% theta_ols # ginv
diag(m+2)[-(1:(m+1)),] %*% sweep.operator(XtX, k = omega_c) %*% diag(m+2)[,-(1:(m+1))] # From sweep operation
# Load libraries
library(MASS)
library(fastmatrix)
library(penalized)
library(ridge)
library(matrixcalc)
########################### Simulate data ###########################
# Generate X
set.seed(1)
n = 100
m = 10
mu = rnorm(m) # Generate mean vector
Sigma = rWishart(n = 1, df = m, Sigma = diag(m))[,,1] # Generate random Covariance matrix
X = mvrnorm(n = n, mu = mu, Sigma = Sigma) # Without intercept column
X_ = cbind(1, X) # With intercept column
# Generate y
THETA = rnorm(m+1)
y = X_ %*% THETA + rnorm(n, sd = 3)
X_y = cbind(X_, y) # Extended X matrix
########################### Exclude operation ###########################
# Exclude columns operation
omega = c(2,4,7)
I = diag(m+1)[,-omega]
X_[,-omega] == X_ %*% I # Equivalent to column exclussion
I %*% t(I) # Unitary matrix with zeros in Ajj for j in omega
t(I) %*% I # Unitary matrix of order m+1-|omega|
head(X_ %*% I %*% t(I)) # substitutes columns in omega by zeros
dim(X_) # 100  11
QR = qr(X_)
R = qr.R(QR, complete = F); dim(R) # 11 11
Q = qr.Q(QR, complete = F); dim(Q) # 100  11
# OLS estimates; can be obtained from normal eq;, Planitz equ., QR or sweep operator.
(theta_ols = coef(lm(y ~ X))) # lm function
solve(t(X_) %*% X_) %*% t(X_) %*% y # From Normal equation
ginv(X_) %*% y # From pseudoinverse
backsolve(R, t(Q) %*% y) # From QR
sweep.operator(t(X_y) %*% X_y, k = 1:(m+1))[1:(m+1),m+2] # From sweep operator.
R[1,1]^2; nrow(X_) # n
R[1,]/R[1,1]; colMeans(X_) # mu
1/(R[1,1]^2 - 1) * (t(R) %*% R - R[1,] %*% t(R[1,])); cov(X_) # covariance matrix
chol((n-1)*cov(X_) + n*colMeans(X_) %*% t(colMeans(X_))); R # R from n, mu and covariance matrix; sign does not match because of sign multiplicity in Cholesky (but does not affect in any way)
omega = c(2,4,7); omega_c = (1:(m+1))[!(1:(m+1) %in% omega)]
# From submodel
(theta_omega = coef(lm(y ~ X[,-(omega-1)]))) # lm function; omega-1 as it does not include the intercept
# From cmb-lm
ginv(R %*% diag(m+1)[,-omega]) %*% R %*% theta_ols # ginv
# From sweep operator
XtX = rbind(cbind(t(R) %*% R, t(R) %*% R %*% theta_ols), c(t(R) %*% R %*% theta_ols, t(y) %*% y))
diag(m+2)[-c(omega, m+2),] %*% sweep.operator(XtX, k = omega_c) %*% diag(m+2)[,-(1:(m+1))]# From sweep operation
# From cmb-lm
ginv(R %*% diag(m+1)[,-omega]) %*% R %*% theta_ols # ginv
diag(m+2)[-c(omega, m+2),] %*% sweep.operator(XtX, k = omega_c) %*% diag(m+2)[,-(1:(m+1))]# From sweep operation
I = diag(m+1)[,-omega]
# Variance of residuals (submodel)
sqrt(sum((y-X_[,-omega] %*% theta_omega)^2)/(n-(m+1)+length(omega)))
# Variance of residuals (cmb-lm)
sigma2_epsilon = (t(y) %*% y - t(theta_omega) %*% t(I) %*% t(R) %*% R %*% I %*% theta_omega)/(n-(m+1)+length(omega))
sigma2_epsilon
# Variance of residuals (submodel)
sqrt(sum((y-X_[,-omega] %*% theta_omega)^2)/(n-(m+1)+length(omega)))
# Variance of residuals (submodel)
sum((y-X_[,-omega] %*% theta_omega)^2)/(n-(m+1)+length(omega))
# Variance of residuals (cmb-lm)
(sigma2_epsilon = (t(y) %*% y - t(theta_omega) %*% t(I) %*% t(R) %*% R %*% I %*% theta_omega)/(n-(m+1)+length(omega)))
# Variance of residuals (sweep operator)
sigma2_epsilon = (t(y) %*% y - t(theta_omega) %*% t(I) %*% t(R) %*% R %*% I %*% theta_omega)/(n-(m+1)+length(omega))
sweep.operator(XtX, k = omega_c)[m+2, m+2] # From sweep operation
sweep.operator(XtX, k = omega_c)[m+2, m+2]/(n-(m+1)+length(omega))) # From sweep operation
sweep.operator(XtX, k = omega_c)[m+2, m+2]/(n-(m+1)+length(omega)) # From sweep operation
# Variance of residuals (submodel)
sum((y-X_[,-omega] %*% theta_omega)^2)/(n-(m+1)+length(omega))
# Variance of residuals (cmb-lm)
(sigma2_epsilon = (t(y) %*% y - t(theta_omega) %*% t(I) %*% t(R) %*% R %*% I %*% theta_omega)/(n-(m+1)+length(omega)))
# Variance of residuals (sweep operator)
sigma2_epsilon = sweep.operator(XtX, k = omega_c)[m+2, m+2]/(n-(m+1)+length(omega)) # From sweep operation
# Variance of residuals (sweep operator)
(sigma2_epsilon = sweep.operator(XtX, k = omega_c)[m+2, m+2]/(n-(m+1)+length(omega))) # From sweep operation
# Standard errors (submodel)
sigma(lm(y ~ X[,-(omega-1)])); sqrt(sigma2_epsilon) # Residual standard error
# Variance of residuals (submodel)
sigma(lm(y ~ X[,-(omega-1)])) # Residual standard error
sum((y-X_[,-omega] %*% theta_omega)^2)/(n-(m+1)+length(omega))
# Variance of residuals (submodel)
sigma(lm(y ~ X[,-(omega-1)]))^2 # Residual standard error
sum((y-X_[,-omega] %*% theta_omega)^2)/(n-(m+1)+length(omega))
# Variance of residuals (cmb-lm)
(sigma2_epsilon = (t(y) %*% y - t(theta_omega) %*% t(I) %*% t(R) %*% R %*% I %*% theta_omega)/(n-(m+1)+length(omega)))
# Variance of residuals (sweep operator)
(sigma2_epsilon = sweep.operator(XtX, k = omega_c)[m+2, m+2]/(n-(m+1)+length(omega))) # From sweep operation
# Standard errors (cmb-lm)
as.numeric(sigma2_epsilon) * ginv(t(I) %*% t(R) %*% R %*% I); unname(vcov(lm(y ~ X[,-(omega-1)]))) # squared standard errors
# Standard errors (submodel)
vcov(lm(y ~ X[,-(omega-1)]))
# Standard errors (cmb-lm)
as.numeric(sigma2_epsilon) * ginv(t(I) %*% t(R) %*% R %*% I); unname(vcov(lm(y ~ X[,-(omega-1)]))) # squared standard errors
chol((n-1)*cov(X_) + n*colMeans(X_) %*% t(colMeans(X_))); R # R from n, mu and covariance matrix; sign does not match because of sign multiplicity in Cholesky (but does not affect in any way)
theta_omega
x0 = X_[1, omega_c] # First sample as example
fit = x0 %*% theta_omega
## Confidence intervals
predict(lm(y ~ X[,-(omega-1)]), interval = 'confidence')[1,] # submodel
add = qt(p = 1-0.05/2, df = n-(m+1)+length(omega))*sqrt(sigma2_epsilon)*sqrt(t(x0) %*% ginv(t(I) %*% t(R) %*% R %*% I) %*% x0)
c(fit = fit, lwr = fit - add, upr = fit + add)
### Prediction intervals
# Submodel
predict(lm(y ~ X[,-(omega-1)]), interval = 'prediction')[1,]
# Cmb-lm
add = qt(p = 1-0.05/2, df = n-(m+1)+length(omega))*sqrt(sigma2_epsilon)*sqrt(t(x0) %*% ginv(t(I) %*% t(R) %*% R %*% I) %*% x0+1)
c(fit = fit, lwr = fit - add, upr = fit + add)
t(x0)
# Cmb-lm
add = qt(p = 1-0.05/2, df = n-(m+1)+length(omega))*sqrt(sigma2_epsilon)*sqrt(x0 %*% ginv(t(I) %*% t(R) %*% R %*% I) %*% t(x0))
x0
dim(x0)
# Cmb-lm
add = qt(p = 1-0.05/2, df = n-(m+1)+length(omega))*sqrt(sigma2_epsilon)*sqrt(t(x0) %*% ginv(t(I) %*% t(R) %*% R %*% I) %*% x0)
c(fit = fit, lwr = fit - add, upr = fit + add)
t(x0)
dim(ginv(t(I) %*% t(R) %*% R %*% I))
x0
dim(x0) = c(1, length(omega_c))
x0
x0 %*% theta_omega
x0 = X_[1, omega_c] # First sample as example
dim(x0) = c(1, length(omega_c))
fit = x0 %*% theta_omega
### Confidence intervals
# Submodel
predict(lm(y ~ X[,-(omega-1)]), interval = 'confidence')[1,]
# Cmb-lm
add = qt(p = 1-0.05/2, df = n-(m+1)+length(omega))*sqrt(sigma2_epsilon)*sqrt(t(x0) %*% ginv(t(I) %*% t(R) %*% R %*% I) %*% x0)
x0 = X_[1, omega_c] # First sample as example
dim(x0) = c(1, length(omega_c))
fit = x0 %*% theta_omega
### Confidence intervals
# Submodel
predict(lm(y ~ X[,-(omega-1)]), interval = 'confidence')[1,]
# Cmb-lm
add = qt(p = 1-0.05/2, df = n-(m+1)+length(omega))*sqrt(sigma2_epsilon)*sqrt(x0 %*% ginv(t(I) %*% t(R) %*% R %*% I) %*% t(x0))
c(fit = fit, lwr = fit - add, upr = fit + add)
### Prediction intervals
# Submodel
predict(lm(y ~ X[,-(omega-1)]), interval = 'prediction')[1,]
# Cmb-lm
add = qt(p = 1-0.05/2, df = n-(m+1)+length(omega))*sqrt(sigma2_epsilon)*sqrt(x0 %*% ginv(t(I) %*% t(R) %*% R %*% I) %*% t(x0)+1)
c(fit = fit, lwr = fit - add, upr = fit + add)
linearRidge
help((theta_ridge = coef(penalized(response = y, penalized = X, lambda1 = 0, lambda2 = lambda))))
